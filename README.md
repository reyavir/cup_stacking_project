EECS 106A Final Project: Autonomous Cup Stacking with Sawyer Robot
In this project, we programmed a Sawyer robot to autonomously stack plastic cups into a pyramid using computer vision and motion planning. Our system consists of two main components: the sensing node and the actuation node. The sensing node detects the number and location of the cups on the table using a webcam, while the actuation node plans the positions for each cup and executes the motion to stack them in a pyramid. We employed homography to map the camera image to real-world coordinates, allowing precise manipulation of the cups.

The project demonstrated the potential for real-world applications, such as automating tasks in construction, warehouses, and restaurants. Additionally, we extended the system to destack cups from the pyramid and incorporated color filtering to selectively stack cups based on color. Our solution effectively met the projectâ€™s design goals, showcasing robust integration of computer vision and robotic control, with further improvements aimed at enhancing speed, accuracy, and adaptability for various cup sizes.

Project Website: https://sites.google.com/berkeley.edu/cup-stacking/home
